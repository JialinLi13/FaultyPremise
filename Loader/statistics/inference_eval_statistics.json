{
    "model_name": "inference",
    "overall_statistics": {
        "active_recognition_count": 0,
        "passive_recognition_count": 0,
        "active_recognition_rate": 0.0,
        "passive_recognition_rate": 0.0,
        "active_recognition_count_no_fsc": 0,
        "active_recognition_applicable_count_no_fsc": 0,
        "active_recognition_rate_no_fsc": 0.0,
        "normal_correctness_count": 0,
        "normal_correctness_rate": 0.0,
        "normal_correctness_applicable_count": 0,
        "normal_answer_avg_len_overall": 0.0,
        "ill_answer_avg_len_overall": 0.0,
        "ill_with_hint_answer_avg_len_overall": 0.0,
        "normal_answer_avg_len_active_success": 0.0,
        "ill_answer_avg_len_active_success": 0.0,
        "normal_answer_avg_len_passive_success": 0.0,
        "ill_with_hint_answer_avg_len_passive_success": 0.0,
        "active_criticism_efficiency_overall": 0.0,
        "passive_criticism_efficiency_overall": 0.0,
        "active_criticism_efficiency_on_success": 0.0,
        "passive_criticism_efficiency_on_success": 0.0,
        "active_success_count": 0,
        "passive_success_count": 0,
        "total_evaluated": 0,
        "valid_for_metrics": 0,
        "invalid_format_count": 0,
        "invalid_format_pids": []
    },
    "statistics_by_difficulty": {},
    "comparative_statistics_by_difficulty": {
        "active_recognition_rate": {},
        "passive_recognition_rate": {},
        "active_recognition_rate_no_fsc": {},
        "normal_correctness_rate": {},
        "normal_answer_avg_len_overall": {},
        "ill_answer_avg_len_overall": {},
        "ill_with_hint_answer_avg_len_overall": {},
        "normal_answer_avg_len_active_success": {},
        "ill_answer_avg_len_active_success": {},
        "normal_answer_avg_len_passive_success": {},
        "ill_with_hint_answer_avg_len_passive_success": {},
        "active_criticism_efficiency_overall": {},
        "passive_criticism_efficiency_overall": {},
        "active_criticism_efficiency_on_success": {},
        "passive_criticism_efficiency_on_success": {},
        "valid_for_metrics": {},
        "active_success_count": {},
        "passive_success_count": {}
    },
    "statistics_by_conflict_type": {},
    "comparative_statistics_by_conflict_type": {
        "active_recognition_rate": {},
        "passive_recognition_rate": {},
        "active_recognition_rate_no_fsc": {},
        "normal_correctness_rate": {},
        "normal_answer_avg_len_overall": {},
        "ill_answer_avg_len_overall": {},
        "ill_with_hint_answer_avg_len_overall": {},
        "normal_answer_avg_len_active_success": {},
        "ill_answer_avg_len_active_success": {},
        "normal_answer_avg_len_passive_success": {},
        "ill_with_hint_answer_avg_len_passive_success": {},
        "active_criticism_efficiency_overall": {},
        "passive_criticism_efficiency_overall": {},
        "active_criticism_efficiency_on_success": {},
        "passive_criticism_efficiency_on_success": {},
        "valid_for_metrics": {},
        "active_success_count": {},
        "passive_success_count": {}
    },
    "statistics_by_conflict_type_and_difficulty": {},
    "notes": "Metrics calculated for successfully parsed evaluation results only. 'invalid_format_count' indicates results skipped due to unexpected main structure (e.g., active/passive True/False missing). Overall average lengths ('_overall') and efficiency ratios ('_overall') are calculated over ALL valid samples in that group (e.g., overall, per difficulty, per conflict type, per conflict type+difficulty). Average lengths on success ('_active_success', '_passive_success') and efficiency 'on_success' are calculated ONLY for samples within that group where the model successfully identified the contradiction in that mode. 'normal_correctness_rate' is the rate of 'True' for 'GPT_eval_result.normal.correctness', EXCLUDING entries with 'conflict_type' of 'irr_query_distraction'. The denominator for 'normal_correctness_rate' is 'normal_correctness_applicable_count'. 'active_recognition_rate_no_fsc' is the rate of 'True' for 'GPT_eval_result.active.if_find_contradiction', EXCLUDING entries with 'conflict_type' of 'flawed_solution_completion'. The denominator for 'active_recognition_rate_no_fsc' is 'active_recognition_applicable_count_no_fsc'. 'comparative_statistics_by_difficulty' and 'comparative_statistics_by_conflict_type' sections show how key metrics vary across difficulty levels and conflict types respectively. 'statistics_by_conflict_type_and_difficulty' contains all metrics for each combination of conflict type and difficulty (only for valid entries)."
}